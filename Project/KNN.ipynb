{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0af57a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Task 01\n",
    "# 1.a: load data frame from file, store into df\n",
    "df = pd.read_csv('KNNAlgorithmDataset.csv')\n",
    "#print(df)\n",
    "\n",
    "#1.c: shuffle the samples\n",
    "df = df.sample(frac=1)\n",
    "# frac = [0,1], incase frac = 0.5, shuffle 50% of the rows\n",
    "#print(df)\n",
    "\n",
    "# convert data frame into array\n",
    "data_array = df.values[:, 1:]  #unselect 1st column / label y\n",
    "\n",
    "# 1.b: set column 'diagnosis' as target variable y / the label\n",
    "y = df[\"diagnosis\"].values\n",
    "#print(y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36f861f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.12857557  0.52134483  0.2241145  ...  2.36764114  2.20543018\n",
      "   2.41359064]\n",
      " [-1.34119789  0.56090497 -1.33328697 ... -1.1710201  -0.04652043\n",
      "  -0.0501966 ]\n",
      " [-0.39969083 -0.37690308 -0.45264049 ... -1.19507812 -1.19029133\n",
      "  -1.31312308]\n",
      " ...\n",
      " [-1.0472432  -0.89118491 -1.04413176 ... -1.06534751 -0.46229005\n",
      "  -0.06959214]\n",
      " [ 1.41231974  1.62902878  1.52943195 ...  1.05815376 -0.95409536\n",
      "   0.4479916 ]\n",
      " [-0.16679919 -1.1471623  -0.18572799 ...  0.21612292  0.12334653\n",
      "  -0.62929189]]\n"
     ]
    }
   ],
   "source": [
    "# Task 01: normalizing the data with z-score normalization\n",
    "\n",
    "mean = data_array.mean(axis=0)\n",
    "standard_deviation = data_array.std(axis=0)\n",
    "\n",
    "normalized_data = (data_array - mean) / standard_deviation\n",
    "\n",
    "print(normalized_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "492f8a27",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Task 02: seperate data into training(70%), validation(20%) and test(10%) sets by slicing\n",
    "da_len = len(data_array)   #number of rows / length of data_array\n",
    "training_set = data_array[:int(da_len * 0.7)]\n",
    "#print(training_set)\n",
    "validation_set = data_array[int(da_len * 0.7): int(da_len * 0.9)]\n",
    "test_set = data_array[int(da_len* 0.9):]\n",
    "#print(len(training_set) + len(validation_set) + len(test_set) == da_len) # the whole data array included in the 3 sets: True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d530e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.c distance algorithms with input of two 1D-Vectors, return distance (real number) of 2 vectors(x1,...,xn)\n",
    "import numpy as np\n",
    "# Manhattan distance\n",
    "def manhattan_distance(vector01, vector02):\n",
    "    # raise error if data points are not of the same length\n",
    "    if (len(vector01) != len(vector02)):\n",
    "        raise ValueError(\"Unequal length of inputed data points\")\n",
    "    # return sum(\\xi_m - xj_m\\)\n",
    "    return np.sum(np.abs(vector01 - vector02))    # np.abs(): absolute value of each elements\n",
    "    # a variante: use np.fabs(v1, v2), return np.sum(np.fabs(vector01 - vector02))\n",
    "\n",
    "# Euclidean distance\n",
    "def euclidean_distance(vector01, vector02):\n",
    "    if (len(vector01) != len(vector02)):\n",
    "        raise ValueError(\"Unequal length of inputed data points\")\n",
    "    # use np library: calculate the norm of the new vector (difference of two old vectors)\n",
    "    return np.linalg.norm(vector01 - vector02)\n",
    "\n",
    "# Chebyshev distance\n",
    "def chebyshev_distance(vector01, vector02):\n",
    "    if (len(vector01) != len(vector02)):\n",
    "        raise ValueError(\"Unequal length of inputed data points\")\n",
    "    # return max(\\xi_01 - xi_02\\)\n",
    "    absolute_array = [np.abs(vector01[i] - vector02[i]) for i in range(len(vector01))]\n",
    "    return max(absolute_array)\n",
    "\n",
    "\n",
    "# test algo with data: \n",
    "#t_p01 = training_set[0]\n",
    "#t_p02 = training_set[1]\n",
    "#t_short01 = [1.1,2,4.43,8]\n",
    "#t_short02 = [3,4.7,6,9.69]\n",
    "\n",
    "#print(manhattan_distance(t_p01, t_p02))    # test (compared with result by online calculator): True\n",
    "#print(euclidean_distance(t_p01, t_p02))    # definition from numpy library\n",
    "#print(chebyshev_distance(t_short01, t_short02))    # test: True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4fbc2464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3: implement the kNN algorithm\n",
    "# accroding to 2.2 kNN algo is capsuled in a kNN predictor\n",
    "class kNN_predictor:\n",
    "    #constructor: define attribiutes\n",
    "    def __init__(self, k, distance_func):    #q: if the k and dist-func is given as param in constructor or later in predict func?\n",
    "        self.trained = False   #default: not trained\n",
    "        self.k = k  # k neighbours\n",
    "        self.d = distance_func\n",
    "        # X(data set) and Y(classes / target values) will be provided in fit() as parameters\n",
    "        self.X = None\n",
    "        self.Y = None\n",
    "        # for the normalization\n",
    "        self.mean = None\n",
    "        self.std = None\n",
    "    \n",
    "    def normalize(self, X):\n",
    "        if self.trained == False:\n",
    "            raise(\"Predictor is not trained! Train it first by calling fit()!\")\n",
    "        return (X - self.mean) / self.std\n",
    "    \n",
    "    # functions\n",
    "    def fit(self, training_X, training_Y):\n",
    "        #feed the model with training data\n",
    "        # TODO: normalize X before storing\n",
    "        self.X = training_X\n",
    "        self.Y = training_Y\n",
    "        self.mean = self.X.mean(axis=0)\n",
    "        self.std = self.X.std(axis=0)\n",
    "        self.trained = True   #set trained\n",
    "\n",
    "        self.X = self.normalize(self.X)\n",
    "        \n",
    "\n",
    "    def predict(self, X, thresh=0.5):\n",
    "        def sort(a):\n",
    "            x,y = a\n",
    "            return x\n",
    "\n",
    "        #predict classification or regression result for new data.\n",
    "        # check if predictor is trained\n",
    "        if self.trained == False:\n",
    "            raise(\"Predictor is not trained! Train it first by calling fit()!\")\n",
    "        \n",
    "        # TODO: call normalize() to normalize the data\n",
    "        X = self.normalize(X)\n",
    "        # TODO: calculate the distance with all the neighbours\n",
    "        kNN = np.array([])\n",
    "        for x1 in X:\n",
    "            dists = np.array([])\n",
    "            for x2 in self.X:\n",
    "                dist = self.d(x1, x2)\n",
    "                np.append(dists, dist)\n",
    "            prob = np.mean(self.Y[np.argsort(dists)])\n",
    "            np.append(kNN, prob[1: self.k+1])\n",
    "            \n",
    "        print(kNN[:, 1])\n",
    "        prob = kNN[:, 1].mean(axis=0)\n",
    "        return prob < thresh\n",
    "\n",
    "    def confusionMatrix(self, X, Y): \n",
    "        #compute confusion matrix, input: X (user input)\n",
    "        '''\n",
    "        if not self.Y:\n",
    "            raise error?\n",
    "        # and validate X and Y shape\n",
    "        # should be Y given or taken from fit?\n",
    "            '''\n",
    "        X = np.array(X)\n",
    "        Y = np.array(Y)\n",
    "        pY = np.array(self.predict(X))\n",
    "\n",
    "        size = len(X)\n",
    "        # calculate entries of the confusion matrix by counting entries where the corresponding condition is given and make it relative to the whole set\n",
    "        TP = len(np.where((Y == 1) & (pY == 1))[0])/size\n",
    "        TN = len(np.where((Y == 0) & (pY == 0))[0])/size\n",
    "        FP = len(np.where((Y == 0) & (pY == 1))[0])/size\n",
    "        FN = len(np.where((Y == 1) & (pY == 0))[0])/size\n",
    "        return [[TP, FN], [FP, TN]]\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa8929ca",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\brock\\Desktop\\Vertiefungspraktika\\Project\\KNN.ipynb Cell 6\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/brock/Desktop/Vertiefungspraktika/Project/KNN.ipynb#X25sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m pred \u001b[39m=\u001b[39m kNN_predictor(\u001b[39m4\u001b[39m, euclidean_distance)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/brock/Desktop/Vertiefungspraktika/Project/KNN.ipynb#X25sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m pred\u001b[39m.\u001b[39mfit(data_array, y)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/brock/Desktop/Vertiefungspraktika/Project/KNN.ipynb#X25sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m pred\u001b[39m.\u001b[39mpredict([data_array[\u001b[39m0\u001b[39m]])\n",
      "\u001b[1;32mc:\\Users\\brock\\Desktop\\Vertiefungspraktika\\Project\\KNN.ipynb Cell 6\u001b[0m line \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/brock/Desktop/Vertiefungspraktika/Project/KNN.ipynb#X25sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m         dist \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39md(x1, x2)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/brock/Desktop/Vertiefungspraktika/Project/KNN.ipynb#X25sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m         np\u001b[39m.\u001b[39mappend(dists, (dist, y))\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/brock/Desktop/Vertiefungspraktika/Project/KNN.ipynb#X25sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m     dists[np\u001b[39m.\u001b[39margsort(sort)]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/brock/Desktop/Vertiefungspraktika/Project/KNN.ipynb#X25sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m     np\u001b[39m.\u001b[39mappend(kNN, dists[\u001b[39m1\u001b[39m:\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mk\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/brock/Desktop/Vertiefungspraktika/Project/KNN.ipynb#X25sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m \u001b[39mprint\u001b[39m(kNN[:, \u001b[39m1\u001b[39m])\n",
      "\u001b[1;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "pred = kNN_predictor(4, euclidean_distance)\n",
    "pred.fit(data_array, y)\n",
    "\n",
    "pred.predict([data_array[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3184e6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# task 3.2: check if user inputs are valid\n",
    "def check_predictor_input(k, d):\n",
    "    valid_dist_algos = ['manhattan', 'euclidean', 'chebyshev']\n",
    "    # there are k training set rows / neighbours for the new data point\n",
    "    if k > len(training_set):\n",
    "        raise ValueError(f\"Given k too large! Give a number not larger than {len(training_set)}\")\n",
    "    if d.lower() not in valid_dist_algos:\n",
    "        raise ValueError(f\"Given algorithm is not valid, please choose from {valid_dist_algos}!\")\n",
    "        \n",
    "#test: passed\n",
    "#check_predictor_input(100, 'manha')\n",
    "#check_predictor_input(400, 'chebyshev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acc579f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 4: test the data with user inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f887c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 5: visualization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
