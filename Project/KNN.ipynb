{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0af57a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.487e+01 1.171e+01 1.048e+01 ... 1.614e+01 1.232e+01 1.386e+01]\n",
      " [2.021e+01 1.719e+01 1.498e+01 ... 1.486e+01 1.239e+01 1.693e+01]\n",
      " [9.612e+01 7.468e+01 6.749e+01 ... 1.043e+02 7.885e+01 9.096e+01]\n",
      " ...\n",
      " [1.017e-01 1.099e-01 9.310e-02 ... 1.129e-01 9.391e-02 1.654e-01]\n",
      " [2.369e-01 2.572e-01 3.020e-01 ... 2.778e-01 2.827e-01 3.630e-01]\n",
      " [6.599e-02 7.097e-02 9.646e-02 ... 7.012e-02 6.771e-02 1.059e-01]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Task 01\n",
    "# 1.a: load data frame from file, store into df\n",
    "df = pd.read_csv('KNNAlgorithmDataset.csv')\n",
    "#print(df)\n",
    "\n",
    "#1.c: shuffle the samples\n",
    "df = df.sample(frac=1)  #??? q01: if re-indexing needed? \n",
    "# frac = [0,1], incase frac = 0.5, shuffle 50% of the rows\n",
    "#print(df)\n",
    "\n",
    "# convert data frame into array\n",
    "data_array = df.values[:, 1:]  #unselect 1st column / label y\n",
    "\n",
    "# 1.b: set column 'diagnosis' as target variable y / the label\n",
    "y = df[\"diagnosis\"].values\n",
    "#print(y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "492f8a27",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Task 02: seperate data into training(70%), validation(20%) and test(10%) sets by slicing\n",
    "da_len = len(data_array)   #number of rows / length of data_array\n",
    "training_set = data_array[:int(da_len * 0.7)]\n",
    "#print(training_set)\n",
    "validation_set = data_array[int(da_len * 0.7): int(da_len * 0.9)]\n",
    "test_set = data_array[int(da_len* 0.9):]\n",
    "#print(len(training_set) + len(validation_set) + len(test_set) == da_len) # the whole data array included in the 3 sets: True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d530e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.c distance algorithms with input of two 1D-Vectors, return distance (real number) of 2 vectors(x1,...,xn)\n",
    "import numpy as np\n",
    "# Manhattan distance\n",
    "def manhattan_distance(vector01, vector02):\n",
    "    # raise error if data points are not of the same length\n",
    "    if (len(vector01) != len(vector02)):\n",
    "        raise ValueError(\"Unequal length of inputed data points\")\n",
    "    # return sum(\\xi_m - xj_m\\)\n",
    "    return np.sum(np.abs(vector01 - vector02))    # np.abs(): absolute value of each elements\n",
    "    # a variante: use np.fabs(v1, v2), return np.sum(np.fabs(vector01 - vector02))\n",
    "\n",
    "# Euclidean distance\n",
    "def euclidean_distance(vector01, vector02):\n",
    "    if (len(vector01) != len(vector02)):\n",
    "        raise ValueError(\"Unequal length of inputed data points\")\n",
    "    # use np library: calculate the norm of the new vector (difference of two old vectors)\n",
    "    return np.linalg.norm(vector01 - vector02)\n",
    "\n",
    "# Chebyshev distance\n",
    "def chebyshev_distance(vector01, vector02):\n",
    "    if (len(vector01) != len(vector02)):\n",
    "        raise ValueError(\"Unequal length of inputed data points\")\n",
    "    # return max(\\xi_01 - xi_02\\)\n",
    "    absolute_array = [np.abs(vector01[i] - vector02[i]) for i in range(len(vector01))]\n",
    "    return max(absolute_array)\n",
    "\n",
    "\n",
    "# test algo with data: \n",
    "#t_p01 = training_set[0]\n",
    "#t_p02 = training_set[1]\n",
    "#t_short01 = [1.1,2,4.43,8]\n",
    "#t_short02 = [3,4.7,6,9.69]\n",
    "\n",
    "#print(manhattan_distance(t_p01, t_p02))    # test (compared with result by online calculator): True\n",
    "#print(euclidean_distance(t_p01, t_p02))    # definition from numpy library\n",
    "#print(chebyshev_distance(t_short01, t_short02))    # test: True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4fbc2464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3: implement the kNN algorithm\n",
    "# accroding to 2.2 kNN algo is capsuled in a kNN predictor\n",
    "class kNN_predictor:\n",
    "    #constructor: define attribiutes\n",
    "    def __init__(self, k, distance_func):    #q: if the k and dist-func is given as param in constructor or later in predict func?\n",
    "        self.trained = False   #default: not trained\n",
    "        self.k = k  # k neighbours\n",
    "        self.d = distance_func\n",
    "        # X(data set) and Y(classes / target values) will be provided in fit() as parameters\n",
    "        self.X = None\n",
    "        self.Y = None\n",
    "        # something about the classification / regression calculated based on data from training set\n",
    "        \n",
    "    # functions\n",
    "    def fit(self, training_X, training_Y):\n",
    "        #feed the model with training data\n",
    "        self.X = training_X\n",
    "        self.Y = training_Y\n",
    "        self.trained = True   #set trained\n",
    "\n",
    "    def predict(self):\n",
    "        #predict classification or regression result for new data.\n",
    "        # check if predictor is trained\n",
    "        if self.trained == False:\n",
    "            raise(\"Predictor is not trained! Train it first by calling fit()!\")\n",
    "            \n",
    "        # TODO: call normalize() to normalize the data\n",
    "        \n",
    "        # TODO: calculate the distance with all the neighbours\n",
    "        \n",
    "        # TODO: choose the k closest neighbours\n",
    "        \n",
    "        # TODO: predict / categorize the data point with 0 or 1\n",
    "        \n",
    "        return None\n",
    "\n",
    "    def confusionMatrix(self, X, Y): \n",
    "        #compute confusion matrix, input: X (user input)\n",
    "        '''\n",
    "        if not self.Y:\n",
    "            raise error?\n",
    "        # and validate X and Y shape\n",
    "        # should be Y given or taken from fit?\n",
    "            '''\n",
    "        X = np.array(X)\n",
    "        Y = np.array(Y)\n",
    "        pY = np.array([0,1,0,1])        #np.array(predict(X))------------Placeholder\n",
    "\n",
    "        size = len(X)\n",
    "        # calculate entries of the confusion matrix by counting entries where the corresponding condition is given and make it relative to the whole set\n",
    "        TP = len(np.where((Y == 1) & (pY == 1))[0])/size\n",
    "        TN = len(np.where((Y == 0) & (pY == 0))[0])/size\n",
    "        FP = len(np.where((Y == 0) & (pY == 1))[0])/size\n",
    "        FN = len(np.where((Y == 1) & (pY == 0))[0])/size\n",
    "        return [[TP, FN], [FP, TN]]\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3184e6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# task 3.2: check if user inputs are valid\n",
    "def check_predictor_input(k, d):\n",
    "    valid_dist_algos = ['manhattan', 'euclidean', 'chebyshev']\n",
    "    # there are k training set rows / neighbours for the new data point\n",
    "    if k > len(training_set):\n",
    "        raise ValueError(f\"Given k too large! Give a number not larger than {len(training_set)}\")\n",
    "    if d.lower() not in valid_dist_algos:\n",
    "        raise ValueError(f\"Given algorithm is not valid, please choose from {valid_dist_algos}!\")\n",
    "        \n",
    "#test: passed\n",
    "#check_predictor_input(100, 'manha')\n",
    "#check_predictor_input(400, 'chebyshev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7b5545ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# task 3.3: make an API, need to be improved\n",
    "class simple_API:\n",
    "    def __init__(self, k, d):\n",
    "        # check if k and d are valid\n",
    "        check_predictor_input(k, d)\n",
    "        self.k = k\n",
    "        self.d = d\n",
    "        \n",
    "        # create predictor with inputs\n",
    "        self.predictor = kNN_predictor(k, d)\n",
    "        \n",
    "        # train the predictor with training data \n",
    "        x = training_set\n",
    "        y = y[:len(training_set)]   #slice the labels for training set\n",
    "        # call predictor.fit() with training data\n",
    "        self.predictor.fit(x, y)\n",
    "   \n",
    "    #predict new data\n",
    "    def predict(self, newdata):\n",
    "        return self.predictor.predict(#something)\n",
    "            \n",
    "    #a func make graphic?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acc579f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 4: test the data with user inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f887c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 5: visualization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
