{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ca065d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0af57a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 01\n",
    "# 1.a: load data frame from file, store into df\n",
    "df = pd.read_csv('KNNAlgorithmDataset.csv')\n",
    "#print(df)\n",
    "\n",
    "#1.c: shuffle the samples\n",
    "df = df.sample(frac=1)\n",
    "# frac = [0,1], incase frac = 0.5, shuffle 50% of the rows\n",
    "#print(df)\n",
    "\n",
    "# convert data frame into array\n",
    "data_array = df.values[:, 1:]  #unselect 1st column / label y\n",
    "\n",
    "# 1.b: set column 'diagnosis' as target variable y / the label\n",
    "y = df[\"diagnosis\"].values\n",
    "#print(y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36f861f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.12108689 -0.40948202 -1.10591706 ... -0.89618001  0.24953342\n",
      "   0.22300338]\n",
      " [ 0.09165373  0.21649904  0.10383912 ...  1.05358578  2.9965249\n",
      "   0.96169623]\n",
      " [ 0.85565191 -0.6724406   0.98984033 ...  2.13771951  1.88510962\n",
      "   1.21660899]\n",
      " ...\n",
      " [-0.09011536  1.03795373 -0.01684817 ...  1.32005124  2.47721732\n",
      "   1.36623169]\n",
      " [ 3.29533386 -0.42577149  3.38710998 ...  2.45138742  1.27682411\n",
      "   0.23297823]\n",
      " [ 2.87499285  0.2118449   3.05758838 ...  1.67787627  0.51970278\n",
      "  -0.21367326]]\n"
     ]
    }
   ],
   "source": [
    "# Task 01: normalizing the data with z-score normalization\n",
    "\n",
    "mean = data_array.mean(axis=0)\n",
    "standard_deviation = data_array.std(axis=0)\n",
    "\n",
    "normalized_data = (data_array - mean) / standard_deviation\n",
    "\n",
    "print(normalized_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "492f8a27",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Task 02: seperate data into training(70%), validation(20%) and test(10%) sets by slicing\n",
    "da_len = len(data_array)   #number of rows / length of data_array\n",
    "\n",
    "training_set = data_array[:int(da_len * 0.7)]\n",
    "training_label = y[:int(da_len * 0.7)]\n",
    "\n",
    "#print(training_set)\n",
    "validation_set = data_array[int(da_len * 0.7): int(da_len * 0.9)]\n",
    "validation_label = y[int(da_len * 0.7): int(da_len * 0.9)]\n",
    "\n",
    "test_set = data_array[int(da_len* 0.9):]\n",
    "test_label = y[int(da_len* 0.9):]\n",
    "#print(len(training_set) + len(validation_set) + len(test_set) == da_len) # the whole data array included in the 3 sets: True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d530e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.c distance algorithms with input of two 1D-Vectors, return distance (real number) of 2 vectors(x1,...,xn)\n",
    "# Manhattan distance\n",
    "def manhattan_distance(vector01, vector02):\n",
    "    # raise error if data points are not of the same length\n",
    "    if (len(vector01) != len(vector02)):\n",
    "        raise ValueError(\"Unequal length of inputed data points\")\n",
    "    # return sum(\\xi_m - xj_m\\)\n",
    "    return np.sum(np.abs(vector01 - vector02))    # np.abs(): absolute value of each elements\n",
    "    # a variante: use np.fabs(v1, v2), return np.sum(np.fabs(vector01 - vector02))\n",
    "\n",
    "# Euclidean distance\n",
    "def euclidean_distance(vector01, vector02):\n",
    "    if (len(vector01) != len(vector02)):\n",
    "        raise ValueError(\"Unequal length of inputed data points\")\n",
    "    # use np library: calculate the norm of the new vector (difference of two old vectors)\n",
    "    return np.linalg.norm(vector01 - vector02)\n",
    "\n",
    "# Chebyshev distance\n",
    "def chebyshev_distance(vector01, vector02):\n",
    "    if (len(vector01) != len(vector02)):\n",
    "        raise ValueError(\"Unequal length of inputed data points\")\n",
    "    # return max(\\xi_01 - xi_02\\)\n",
    "    absolute_array = [np.abs(vector01[i] - vector02[i]) for i in range(len(vector01))]\n",
    "    return max(absolute_array)\n",
    "\n",
    "\n",
    "# test algo with data: \n",
    "#t_p01 = training_set[0]\n",
    "#t_p02 = training_set[1]\n",
    "#t_short01 = [1.1,2,4.43,8]\n",
    "#t_short02 = [3,4.7,6,9.69]\n",
    "\n",
    "#print(manhattan_distance(t_p01, t_p02))    # test (compared with result by online calculator): True\n",
    "#print(euclidean_distance(t_p01, t_p02))    # definition from numpy library\n",
    "#print(chebyshev_distance(t_short01, t_short02))    # test: True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1b0c591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# task 3.2: check if user inputs are valid\n",
    "def check_predictor_input(k, d):\n",
    "    valid_dist_algos = ['manhattan', 'euclidean', 'chebyshev']\n",
    "    # there are k training set rows / neighbours for the new data point\n",
    "    if k > len(training_set):\n",
    "        raise ValueError(f\"Given k too large! Give a number not larger than {len(training_set)}\")\n",
    "    if d.lower() not in valid_dist_algos:\n",
    "        raise ValueError(f\"Given algorithm is not valid, please choose from {valid_dist_algos}!\")\n",
    "        \n",
    "#test: passed\n",
    "#check_predictor_input(100, 'manha')\n",
    "#check_predictor_input(400, 'chebyshev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4fbc2464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3: implement the kNN algorithm\n",
    "# accroding to 2.2 kNN algo is capsuled in a kNN predictor\n",
    "class kNN_predictor:\n",
    "    #constructor: define attribiutes\n",
    "    def __init__(self, k, distance_func):    #q: if the k and dist-func is given as param in constructor or later in predict func?\n",
    "        check_predictor_input(k, distance_func)\n",
    "        self.trained = False   #default: not trained\n",
    "        self.k = k  # k neighbours\n",
    "        if (distance_func == 'manhattan'):\n",
    "            self.dname = 'Manhattan distance'\n",
    "            self.d = manhattan_distance\n",
    "        elif (distance_func == 'euclidean'):\n",
    "            self.dname = 'Euclidean distance'\n",
    "            self.d = euclidean_distance\n",
    "        elif (distance_func == 'chebyshev'):\n",
    "            self.dname = 'Chebyshev distance'\n",
    "            self.d = chebyshev_distance\n",
    "        else:\n",
    "            raise ValueError(\"Invalid function\")\n",
    "        # X(data set) and Y(classes / target values) will be provided in fit() as parameters\n",
    "        self.X = None\n",
    "        self.Y = None\n",
    "        # for the normalization\n",
    "        self.mean = None\n",
    "        self.std = None\n",
    "    \n",
    "    def normalize(self, X):\n",
    "        if self.trained == False:\n",
    "            raise(\"Predictor is not trained! Train it first by calling fit()!\")\n",
    "        return (X - self.mean) / self.std\n",
    "    \n",
    "    # functions\n",
    "    def fit(self, training_X, training_Y):\n",
    "        #feed the model with training data\n",
    "        # TODO: normalize X before storing\n",
    "        self.X = training_X\n",
    "        self.Y = training_Y\n",
    "        self.mean = self.X.mean(axis=0)\n",
    "        self.std = self.X.std(axis=0)\n",
    "        self.trained = True   #set trained\n",
    "\n",
    "        self.X = self.normalize(self.X)\n",
    "        \n",
    "\n",
    "    def predict(self, X, thresh=0.5):\n",
    "        # check if predictor is trained\n",
    "        if self.trained == False:\n",
    "            raise(\"Predictor is not trained! Train it first by calling fit()!\")\n",
    "        \n",
    "        # TODO: call normalize() to normalize the data\n",
    "        X = self.normalize(X)\n",
    "        # TODO: calculate the distance with all the neighbours\n",
    "        kNN = []\n",
    "        for x1 in X:\n",
    "            dists = []\n",
    "            for x2 in self.X:\n",
    "                dist = self.d(x1, x2)\n",
    "                dists.append(dist)\n",
    "            nearest_indexes = np.argsort(dists)\n",
    "            nearest_labels = self.Y[nearest_indexes]\n",
    "            prob = np.mean(nearest_labels[1:self.k+1])\n",
    "            kNN.append(prob)\n",
    "        return np.array(kNN) > thresh\n",
    "\n",
    "    def confusionMatrix(self, X, Y): \n",
    "        #compute confusion matrix, input: X (user input)\n",
    "        '''\n",
    "        if not self.Y:\n",
    "            raise error?\n",
    "        # and validate X and Y shape\n",
    "        # should be Y given or taken from fit?\n",
    "            '''\n",
    "        X = np.array(X)\n",
    "        Y = np.array(Y)\n",
    "        pY = np.array(self.predict(X))\n",
    "\n",
    "        size = len(X)\n",
    "        # calculate entries of the confusion matrix by counting entries where the corresponding condition is given and make it relative to the whole set\n",
    "        TP = len(np.where((Y == 1) & (pY == 1))[0])/size\n",
    "        TN = len(np.where((Y == 0) & (pY == 0))[0])/size\n",
    "        FP = len(np.where((Y == 0) & (pY == 1))[0])/size\n",
    "        FN = len(np.where((Y == 1) & (pY == 0))[0])/size\n",
    "        return [[TP, FN], [FP, TN]]\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa8929ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10.18  14.45  17.14  12.31   9.333 12.05  10.26  15.53  12.27  13.61\n",
      " 12.4   11.5   12.21  14.22  10.16  11.04  20.57   9.676 15.75  16.35\n",
      " 21.71  18.46  12.9   23.27  18.03  12.77  14.06  13.54  13.15  12.34\n",
      " 19.59  11.68  14.59  11.61  13.85  13.96  11.54  15.49  11.71  17.85\n",
      " 15.12  14.04  15.46  17.2   15.78  17.06  20.51  12.32   9.755 17.29\n",
      " 10.66  14.58  15.28  12.95  12.88  14.86  15.    10.44  23.29  12.91\n",
      " 13.    14.64  14.29  18.08  13.21  20.92  14.86  18.22  12.72  11.71\n",
      " 12.03  20.34  16.3   12.8    9.904 15.75  19.55  11.45  10.82  11.89\n",
      " 10.48  13.82  16.13  15.05  10.88  11.93  11.06  12.36  15.85  12.46\n",
      " 13.65  12.1   19.79  12.18  11.13   8.598  8.95  11.84  20.55  11.47\n",
      " 11.08  10.08  13.46  13.53   8.618 13.68   8.734 13.88  13.48  13.94\n",
      " 11.94  18.49  12.    20.58  12.3    9.668 16.6   17.57  13.51  14.97\n",
      " 10.26   9.787 13.28  15.78  10.65  12.89  10.94  11.93  14.53  13.05\n",
      " 11.95  21.56  18.25  12.85  17.6    8.219 13.27  11.22  13.05  14.26\n",
      " 12.47  27.22  14.74  13.4   15.27  11.75  12.87  13.9    9.504 10.57\n",
      " 11.81  10.49  21.61  11.57  13.73  19.21   9.042  9.436 14.2   11.14\n",
      " 12.62  11.8    8.888 15.3   11.6   17.75  11.16  16.02  13.5   19.81\n",
      " 16.13  11.71  17.46  13.7   13.38  14.81  12.45  14.42  22.27  16.65\n",
      " 20.44  12.98  13.    15.66  19.55  14.47  12.36  13.86  12.22  13.62\n",
      " 12.76  11.25  11.74  21.37  19.59  11.06  11.52  14.99  13.64  14.8\n",
      " 12.7   12.21  14.03  13.17  15.46  13.3   13.98  20.64  11.6   15.73\n",
      " 18.63  16.25  16.26  10.17  20.29  17.99  13.16  16.14   7.729 11.66\n",
      " 18.81  12.34  12.81  11.62  13.59  18.05  14.92  18.66  14.34  12.39\n",
      " 15.06  19.17  19.53  13.45  13.46  16.27  13.87  12.3   12.99  13.2\n",
      " 11.13  28.11  12.18  21.16  12.23  12.58  12.45  20.2   19.4   13.4\n",
      " 11.51  12.65  20.09  11.41  13.44  11.46  10.29  12.04  13.24  11.8\n",
      " 20.59  13.85  17.54  17.99   9.777 11.15  23.21  14.87   9.606 17.93\n",
      " 18.61  20.47  15.71  17.35  10.71  14.41  14.54  20.6   19.07  19.68\n",
      " 15.46  14.22  13.77   9.847 17.02  13.8   17.3   11.28  13.17  10.8\n",
      " 17.05   9.683 14.69  12.78  13.34  14.6   13.14  10.96  13.87  17.42\n",
      " 20.16  14.97  16.03  11.67  12.87  14.87  10.48   9.268 11.08  11.27\n",
      " 12.42  16.46  18.01  12.54  13.43  16.5   11.49  10.86  10.49  19.19\n",
      "  8.597 18.65  13.71  12.96  11.7    9.    18.31  19.8   15.1   12.94\n",
      " 11.54  20.48  27.42  10.51   9.876 19.89  11.99  15.04  14.9   13.69\n",
      " 14.68  19.45  16.78  18.94  12.19  11.27  16.11  14.64  13.66  16.07\n",
      " 14.62  12.62  10.25  10.32  11.37  13.9   10.95  19.27  10.26  19.18\n",
      " 11.29  14.99   9.397 14.71  14.53  11.43  14.96  12.56  11.42  18.82\n",
      " 16.69  10.57  14.44  17.19  15.61  11.76  12.86  10.97  21.75  12.46\n",
      " 12.47   8.571 10.51  11.41  12.67  13.28  13.61  21.09  20.94  13.71\n",
      " 14.5   14.4   11.87  11.26  12.68  20.26   9.029 11.76 ] [[1.753e+01 6.512e+01 3.131e+02 ... 5.575e-02 3.055e-01 8.797e-02]\n",
      " [2.022e+01 9.449e+01 6.427e+02 ... 1.838e-01 4.753e-01 1.013e-01]\n",
      " [1.640e+01 1.160e+02 9.127e+02 ... 2.550e-01 4.066e-01 1.059e-01]\n",
      " ...\n",
      " [2.303e+01 1.324e+02 1.264e+03 ... 1.573e-01 3.689e-01 8.368e-02]\n",
      " [1.733e+01 5.879e+01 2.505e+02 ... 1.750e-01 4.228e-01 1.175e-01]\n",
      " [1.814e+01 7.500e+01 4.311e+02 ... 7.160e-02 1.978e-01 6.915e-02]]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'numpy.float64' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\brock\\Desktop\\Vertiefungspraktika\\Project\\KNN.ipynb Cell 8\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/brock/Desktop/Vertiefungspraktika/Project/KNN.ipynb#X64sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(training_set[:,\u001b[39m0\u001b[39m],training_set[:,\u001b[39m1\u001b[39m:])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/brock/Desktop/Vertiefungspraktika/Project/KNN.ipynb#X64sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m pred\u001b[39m.\u001b[39mfit(training_set[:,\u001b[39m0\u001b[39m], training_set[:,\u001b[39m1\u001b[39m:])\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/brock/Desktop/Vertiefungspraktika/Project/KNN.ipynb#X64sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m pred\u001b[39m.\u001b[39mpredict([data_array[\u001b[39m0\u001b[39m]])\n",
      "\u001b[1;32mc:\\Users\\brock\\Desktop\\Vertiefungspraktika\\Project\\KNN.ipynb Cell 8\u001b[0m line \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/brock/Desktop/Vertiefungspraktika/Project/KNN.ipynb#X64sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m dists \u001b[39m=\u001b[39m []\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/brock/Desktop/Vertiefungspraktika/Project/KNN.ipynb#X64sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m \u001b[39mfor\u001b[39;00m x2 \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mX:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/brock/Desktop/Vertiefungspraktika/Project/KNN.ipynb#X64sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m     dist \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39md(x1, x2)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/brock/Desktop/Vertiefungspraktika/Project/KNN.ipynb#X64sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m     dists\u001b[39m.\u001b[39mappend(dist)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/brock/Desktop/Vertiefungspraktika/Project/KNN.ipynb#X64sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m nearest_indexes \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margsort(dists)\n",
      "\u001b[1;32mc:\\Users\\brock\\Desktop\\Vertiefungspraktika\\Project\\KNN.ipynb Cell 8\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/brock/Desktop/Vertiefungspraktika/Project/KNN.ipynb#X64sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmanhattan_distance\u001b[39m(vector01, vector02):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/brock/Desktop/Vertiefungspraktika/Project/KNN.ipynb#X64sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39m# raise error if data points are not of the same length\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/brock/Desktop/Vertiefungspraktika/Project/KNN.ipynb#X64sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39mif\u001b[39;00m (\u001b[39mlen\u001b[39m(vector01) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(vector02)):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/brock/Desktop/Vertiefungspraktika/Project/KNN.ipynb#X64sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mUnequal length of inputed data points\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/brock/Desktop/Vertiefungspraktika/Project/KNN.ipynb#X64sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39m# return sum(\\xi_m - xj_m\\)\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'numpy.float64' has no len()"
     ]
    }
   ],
   "source": [
    "pred = kNN_predictor(4, 'manhattan')\n",
    "print(training_set[:,0],training_set[:,1:])\n",
    "pred.fit(training_set[:,0], training_set[:,1:])\n",
    "pred.predict([data_array[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acc579f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 4: test the data with user inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f887c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 5: visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e13f4ae",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
